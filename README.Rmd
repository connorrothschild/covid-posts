---
title: "A Shiny App for 400+ Blog Posts on COVID-19 with R"
author: "Rees Morrison and Conor Rothschild"
date: "October 28, 2020" 
output: github_document
--- 

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      dpi = 300)

library(tidyverse) # for a collection of frequently used packages that follow a similar coding approach
library(funModeling) # to compare vectors against each other, to find overlaps and inconsistencies
library(ggpmisc) # to put tables in plots
library(ggrepel) # to spread points or text so that they do not overlap on a plot
library(readxl) # to read in the underlying Excel data about the COVID-19 blog posts in R
library(viridis) # to use various palettes in ggplot
library(tidytext) # text-mining functions that help analyse the content of posts

library(cr)
set_cr_theme()
```


Our goal here is to help bloggers who want to analyze COVID-19 data by unleashing R and the resources of its community by being able to researching such posts (here, called "covidRposts). 

Having so far found 423 covidRposts in English, we have published a Shiny app for them. It lets users find the names of the 231 bloggers who wrote those covidRposts, their roles, and country. The app also lets users interactively search the collection of posts by primary topic, title, date, and whether the post used a particular mathematical technique and which source of data. To learn more about the evolution of this data set, one of the authors has published nine articles on Medium. The most recent Medium article links to the series https://medium.com/@rees_32356/my-previous-nine-articles-have-each-focused-on-a-different-finding-from-an-ever-growing-set-of-e774fb608dbd 

If anyone has corrections to the data set or knows other blog posts that ought to be included in it, please write Rees (at) ReesMorrison (dot) com. The data set analyzed in this post is available on GitHub [ ]. 

The remainder of this post highlights some of the findings from the data set of COVID-19posts. The first plot displays the pace of blog postings. It shows the week of the year on the x-axis, starting in early-February, and the number of posts on the y-axis. As the pandemic has ground on and on, fewer bloggers have seized upon the data it has generated.

```{r weekly, echo = FALSE, warnings = FALSE}
posts <- readxl::read_excel(here::here("data/postsTopicsRoles1019.xlsx"))

month <- seq(as.Date("2020-01-01"),
             as.Date("2020-12-01"),
             by = "1 month")

month_numeric <- lubridate::yday(month) / 365 * 52 + 1
month_label <- lubridate::month(month, label = TRUE)

ggplot(posts, aes(x = Week)) +
  geom_histogram(stat = "count",
                 # fill = "firebrick",
                 color = "white",
                 width = 0.7,) +
  labs(
    x = element_blank(),
    y = "Number of Blog Posts",
    title = "Blog Posts that Use R to Analyze Covid-19 Data",
    subtitle = "Posts in English only, as of Oct. 20, 2020",
    caption = "Source: Rees Morrison compilation of COVID-19 blog posts that use R"
  ) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(breaks = month_numeric,
                     labels = month_label)

# ggsave("C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/COVID-19/MyPosts/Weekly.png", height = 6.5, width = 6.5, units = "in", dpi = 600)
```

Some bloggers have been prolific; many more have been one and done. For the 23 bloggers who have published at least four covidRposts, the plot below shows their names and their posts by week of 2020. For an example of how to read the plot, Tim Churches, at the bottom of the reverse alphabetical y-axis, has published a total of six posts, but none after early April. Note that the text boxes with the months are somewhat approximately located on the plot.

The color of the points corresponds to the work role of the blogger as explained in the legend at the bottom. It is immediately apparent that professors (blue) and academic researchers (red) predominate in this group of bloggers. If you include the postgraduate students, universities writ large account for nearly all of the prolific bloggers.

```{r prolificVer2}
# which bloggers have the most posts and set a cutoff (4); those are "freqBloggers"
prolific <-
  posts %>% select(LastName, Week) %>% group_by(LastName) %>% summarise(Count = n()) %>%
  arrange(desc(Count)) %>% ungroup()

freqBloggers <- prolific$LastName[1:13]

graphProlific <-
  posts %>% select(LastName, Week, Role) %>% 
  dplyr::filter(LastName %in% freqBloggers)
# graphProlific$Role <- str_replace(graphProlific$Role, pattern = "wrote Nancy", replacement = "Unknown")

graphProlific %>% 
  mutate(LastName = fct_reorder(LastName, -desc(Role))) %>%
  ggplot(aes(x = Week, y = LastName, colour = Role)) +
  geom_point(pch = 20, size = 4) +
  # geom_jitter(pch = 20, size = 4, width = 0.1) +
  labs(
    x = element_blank(),
    y = element_blank(),
    colour = element_blank(),
    title = "Timing of Blog Posts that Use R to Analyze COVID-19 Data",
    subtitle = "Role of bloggers identified to date with more than four posts",
    caption = "Source: Rees Morrison compilation of COVID-19 blog posts that use R"
  ) +
  scale_x_continuous(breaks = month_numeric,
                     labels = month_label) +
  theme(legend.position = "bottom",
        legend.direction = 'horizontal')

# ggsave("C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/COVID-19/MyPosts/prolific.png", height = 6.5, width = 6.5, units = "in", dpi = 600)
```

We should explain "Role" a bit more. Bloggers, other than professors, describe their work-day roles in a variety of ways. One of the authors (Rees) standardized the multitude of terms and descriptions, but it is quite possible that this effort misrepresented what some of these bloggers do for a living. We welcome corrections. 

Going further, the next plot assigned the bloggers into the broader role categories. Those broader categories are represented as columns in the following chart, with the segments showing the more granular roles. The labels indicate the number of posts in the data set for each role within a role category.

```{r authorVer2, echo = FALSE, warnings = FALSE}
# read in information about roles, country, geo, etc.
roles <-
  read_excel(here::here("data/NamesRolesEmailsTwo.Ver1.xls"), trim_ws = TRUE)

posts <- left_join(posts, roles[, 1:6])

roleSum <-
  posts %>% group_by(CoreRole, Role) %>% summarise(NumPosts = length(Author)) %>%
  arrange(desc(NumPosts)) %>% ungroup() #30

ggplot(posts, aes(x = CoreRole, fill = Role)) +
  geom_bar(stat = "count", width = 0.7) +
  labs(
    x = "Roles of Bloggers",
    y = "Number of Blog Posts",
    title = "Blog Posts that Use R to Analyze Covid-19 Data",
    subtitle = "Role (position) of those who posted, as of Oct. 19, 2020",
    caption = "Source: Rees Morrison compilation of COVID-19 blog posts that use R"
  ) +
  scale_y_continuous(expand = c(0, 0)) +
  geom_text(
    stat = "count",
    aes(label = ..count..),
    color = "black",
    group = "Role",
    position = "stack",
    hjust = 1
  ) +
  scale_x_discrete(expand = c(0, 0)) +
  theme(legend.position = "bottom",
        legend.direction = 'horizontal')

# ggsave("C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/COVID-19/MyPosts/Roles.png", height = 6.5, width = 6.5, units = "in", dpi = 600)
```

The more data sources the R community knows for purposes of exploring the coronavirus pandemic, the richer will be the insights. Data mashups can shed new light on an issue; inconsistencies between data sets can yield improvements; or better indices can be constructed. For that reason, one of the authors (Rees) extracted from the collection of blog posts information about their data sources.

For the most part, the bloggers identified the data source they drew on for their analysis. However, standardizing that range of nearly 140 data sources was a challenge

One takeaway can't help but notice the absence of the U.S. CDC agency. The other takeaway commends the dominance of Johns Hopkins, who early, comprehensively and consistently has set the standard for COVID-19 data collection and dissemination to the public.

```{r datasourcesVer2}
postsConnor <-
 read.csv(here::here("data/postsOct20423allText.csv")) # this has 442 obs as mistakes

textDF.Data <- postsConnor %>% # 592 obs. of 3 vars June 20
 mutate(data = str_extract_all(postsConnor$text, pattern = "(?<=\\&Data).*?(?=&&)")) %>%
 unnest()

# textDF.Data$data <- stringr::str_trim(string = textDF.Data$data, side = "both")
textDF.Data$data <- str_squish(string = textDF.Data$data)

textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "ACAPS$", replacement = "Assessment Capacities Project (ACAPS)")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "Apple Mobility Data", replacement = "Apple Mobility")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Apple.*$", replacement = "Apple Mobility")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Assessment.*$", replacement = "Assessment Capacities Project (ACAPS)")
textDF.Data$data <-
 ifelse(
 str_detect(textDF.Data$data, pattern = "Labor Statistics"),
 "U.S. Bureau of Labor Statistics",
 textDF.Data$data
 )
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "corona virus package", replacement = "coronavirus package")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Covid Tracking.*$", replacement = "COVID Tracking Project")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "covidtracking.com", replacement = "COVID Tracking Project")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "COVID Tracking project", replacement = "COVID Tracking Project")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "COVID-19 package",
 replacement = "COVID-19 package")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "COVID-19R",
 replacement = "COVID-19 package")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "Centers",
 replacement = "Centre")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "data.gouv.fr/fr/datasets/
",
replacement = "data.gouv.fr")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "gouv.fr",
 replacement = "data.gouv.fr")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^European Centre.*$", replacement = "European Centre for Disease Control (ECDC)")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "European Center for Disease Control", replacement = "European Centre for Disease Control (ECDC)")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^ECDC.*$", replacement = "European Centre for Disease Control (ECDC)")
textDF.Data$data <- str_replace(
 textDF.Data$data,
 pattern = "
European Centre for Disease Control (ECDC) (ECDC)",
replacement = "European Centre for Disease Control (ECDC)"
)
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "french site data.data.gouv.fr",
 replacement = "data.gouv.fr")
textDF.Data$data <-
 str_remove(textDF.Data$data, pattern = "Geocodes from ")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Google Mob.*$", replacement = "Google Mobility")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "Google mobility", replacement = "Google Mobility")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = 'Google \\"COVID-19 Community Mobility Reports\\"', replacement = "Google Mobility")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Hopkins.*$", replacement = "Johns Hopkins Univ.")
textDF.Data$data <-
 str_remove(string = textDF.Data$data, pattern = "https\\:")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Human Mortality.*$", replacement = "Human Mortality Database")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "I n stituto", replacement = "Instituto")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Japan National.*$", replacement = "Japan National Land Numeric Information")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "Johns Hopkins$", replacement = "Johns Hopkins Univ.")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "microsimulation", replacement = "Simulation")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^Mobility Trends.*$", replacement = "Apple Mobility")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^New York T.*$", replacement = "New York Times")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "Not sourced", replacement = "No data")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "Opentable",
 replacement = "OpenTable")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "our world in data",
 replacement = "Our World in Data")
textDF.Data$data <-
 str_remove(string = textDF.Data$data, pattern = "regression, log-linear")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "^The Guard.*$", replacement = "The Guardian (Australia)")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "the united states project",
 replacement = "United States Project")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "simulation", replacement = "Simulation")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "S imulation", replacement = "Simulation")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "T ennessee", replacement = "Tennessee")
textDF.Data$data <-
 str_replace(textDF.Data$data, pattern = "U nited S tates P roject", replacement = "United States Project")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "US Census",
 replacement = "U.S. Census Bureau")
textDF.Data$data <-
 ifelse(
 str_detect(textDF.Data$data, pattern = "Census"),
 "U.S. Census Bureau",
 textDF.Data$data
 )
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "Wikipedia: Case statistics\\)",
 replacement = "Wikipedia")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "Wikipeida",
 replacement = "Wikipedia")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "W ikipeida",
 replacement = "Wikipedia")
textDF.Data$data <-
 ifelse(str_detect(textDF.Data$data, pattern = "Wikipedia"),
 "Wikipedia",
 textDF.Data$data)
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "W ikipedia",
 replacement = "Wikipedia")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "US Census Bureau",
 replacement = "U.S. Census Bureau")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "Worldbank",
 replacement = "World Bank")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "WorldBank",
 replacement = "World Bank")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "World o meters",
 replacement = "Worldometers")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "W orldometers",
 replacement = "Worldometers")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "^World Pop.*$",
 replacement = "World Population Review (WPR)")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "WorldPop",
 replacement = "World Population Review (WPR)")
textDF.Data$data <-
 str_replace(string = textDF.Data$data,
 pattern = "www.insee.fr",
 replacement = "INSEE")
textDF.Data$data <-
 str_remove(string = textDF.Data$data, pattern = "www\\.")

# group and count
textDF.Data.gat <-
 textDF.Data %>% group_by(data) %>% summarise(Count = n()) %>%
 arrange(desc(Count)) %>% ungroup() #46 obs; 52 7/8; 137 10/19
```
```{css}
.header {
  text-transform: uppercase;
  font-size: 12px;
  font-weight: 400;
  border-bottom: 2px solid #555;
}
```


```{r dataTable}
library(reactable)

reactable(
  textDF.Data.gat,
  compact = TRUE,
  striped = TRUE,
  defaultColDef = colDef(headerClass = "header",
                         na = "–"),
  columns = list(data = colDef(name = 'Data Source'))
)

# group and count
textDF.Data.gat <- textDF.Data %>% filter(data %nin% c("Simulation", "No data")) %>%
 group_by(data) %>% summarise(Count = n()) %>%
 arrange(desc(Count)) %>% ungroup() 

ggplot(subset(textDF.Data.gat, Count > 3), aes(x = reorder(data, Count), y = Count)) +
 geom_col(width = 0.7) +
 labs(x = NULL, y = "Number of Blogs Using Data", title = "Blog Posts that Use R to Analyze Covid-19 Data", subtitle = "Sources of data used more than three times, as of Oct. 19, 2020", caption = "Source: Rees Morrison compilation of COVID-19 blog posts that use R") +
 scale_y_continuous(expand = c(0,0)) +
 scale_x_discrete(expand = c(0,0)) +
 coord_flip()
```

Bloggers and other analysts would like a thumbnail summary of blogs. Assigning each blog post a primary topic introduces a fair amount of subjectivity, to be sure, but the hope is that these broad topics will help researchers find content and colleagues who share similar interests. Here, a heat map shows nine categories that the 160+ blogs address as their primary topic. Epidemiology leads the way, as might be expected, but also quite a few posts seem to take the Covid data as an opportunity to show off a capability of the R programming language ("DataViz", "R Program" and "Statistics").

```{r topicsVer2}
# remove NAs and gather
topics.gat <- posts %>% dplyr::filter(CoreRole != "NA" & Country != "NA") %>% group_by(CoreRole, Topic) %>% summarise(Count = n()) %>% ungroup() # 41 obs

# 423-sum(topics.gat$Count) #15

ggplot(topics.gat, aes(x = Topic, y = CoreRole, fill = Count)) +
 geom_tile() +
 scale_fill_gradient2(midpoint = 6, mid = "grey", limits = c(0,12)) +
 #scale_fill_gradientn(colours = c("darkred", "orange", "yellow", "white")) +
 # scale_fill_gradientn(colours = scales::muted(rainbow(5))) +
 # scale_fill_gradientn(colours = rainbow(5)) +
 labs(x = "Primary Topic", y = NULL, title = "Blog Posts that Use R to Analyze Covid-19 Data", subtitle = "Primary topics and sector of blogger (389 posts, 34 unknowns excluded)", caption = "R Morrison compilation of COVID-19 blog posts that use R", fill = element_blank()) +
 theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
 theme(legend.position = "bottom",
 legend.direction = 'horizontal')

# ggsave("C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/COVID-19/MyPosts/RoleCtryHeatmap.png", height = 6.5, width = 6.5, units = "in", dpi = 600)

```

